{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4962ddc1-9ee5-4e23-afba-4baa08490c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model.utils as model_utils\n",
    "import mlflow\n",
    "import utils\n",
    "from data.dataset import SeparationDataset\n",
    "from data.musdb import get_musdb_folds\n",
    "from data.utils import crop_targets, random_amplify\n",
    "from model.waveunet import Waveunet\n",
    "from test import evaluate, validate\n",
    "from os import environ as env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1058462-0a4f-481a-ba9c-93dff394c49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load env variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o -v ./config/config_train.yml\n",
    "# %reload_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30552b87-7c2a-468e-98b0-db5a2eaa4c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # torch.backends.cudnn.benchmark=True # This makes dilated conv much faster for CuDNN 7.5\n",
    "\n",
    "    # MODEL\n",
    "    num_features = [args.features * i for i in range(1, args.levels + 1)] if args.feature_growth == \"add\" else \\\n",
    "        [args.features * 2 ** i for i in range(0, args.levels)]\n",
    "    target_outputs = int(args.output_size * args.sr)\n",
    "    model = Waveunet(args.channels, num_features, args.channels, args.instruments, kernel_size=args.kernel_size,\n",
    "                     target_output_size=target_outputs, depth=args.depth, strides=args.strides,\n",
    "                     conv_type=args.conv_type, res=args.res, separate=args.separate)\n",
    "\n",
    "    if args.cuda:\n",
    "        model = model_utils.DataParallel(model)\n",
    "        print(\"move model to gpu\")\n",
    "        model.cuda()\n",
    "\n",
    "    print('model: ', model)\n",
    "    print('parameter count: ', str(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "    writer = SummaryWriter(args.log_dir)\n",
    "\n",
    "    ### DATASET\n",
    "    musdb = get_musdb_folds(args.dataset_dir)\n",
    "    # If not data augmentation, at least crop targets to fit model output shape\n",
    "    crop_func = partial(crop_targets, shapes=model.shapes)\n",
    "    # Data augmentation function for training\n",
    "    augment_func = partial(random_amplify, shapes=model.shapes, min=0.7, max=1.0)\n",
    "    train_data = SeparationDataset(musdb, \"train\", args.instruments, args.sr, args.channels, model.shapes, True,\n",
    "                                   args.hdf_dir, audio_transform=augment_func)\n",
    "    val_data = SeparationDataset(musdb, \"val\", args.instruments, args.sr, args.channels, model.shapes, False,\n",
    "                                 args.hdf_dir, audio_transform=crop_func)\n",
    "    test_data = SeparationDataset(musdb, \"test\", args.instruments, args.sr, args.channels, model.shapes, False,\n",
    "                                  args.hdf_dir, audio_transform=crop_func)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n",
    "                                             num_workers=args.num_workers, worker_init_fn=utils.worker_init_fn)\n",
    "\n",
    "    ##### TRAINING ####\n",
    "\n",
    "    # Set up the loss function\n",
    "    if args.loss == \"L1\":\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.loss == \"L2\":\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"Couldn't find this loss!\")\n",
    "\n",
    "    # Set up optimiser\n",
    "    optimizer = Adam(params=model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Set up training state dict that will also be saved into checkpoints\n",
    "    state = {\"step\": 0,\n",
    "             \"worse_epochs\": 0,\n",
    "             \"epochs\": 0,\n",
    "             \"best_loss\": np.Inf}\n",
    "\n",
    "    # LOAD MODEL CHECKPOINT IF DESIRED\n",
    "    if args.load_model is not None:\n",
    "        print(\"Continuing training full model from checkpoint \" + str(args.load_model))\n",
    "        state = model_utils.load_model(model, optimizer, args.load_model, args.cuda)\n",
    "\n",
    "    print('TRAINING START')\n",
    "\n",
    "    while state[\"worse_epochs\"] < args.patience:\n",
    "        print(\"Training one epoch from iteration \" + str(state[\"step\"]))\n",
    "        avg_time = 0.\n",
    "        model.train()\n",
    "        with tqdm(total=len(train_data) // args.batch_size) as pbar:\n",
    "            np.random.seed()\n",
    "            for example_num, (x, targets) in enumerate(dataloader):\n",
    "                if args.cuda:\n",
    "                    x = x.cuda()\n",
    "                    for k in list(targets.keys()):\n",
    "                        targets[k] = targets[k].cuda()\n",
    "\n",
    "                t = time.time()\n",
    "\n",
    "                # Set LR for this iteration\n",
    "                utils.set_cyclic_lr(optimizer, example_num, len(train_data) // args.batch_size, args.cycles,\n",
    "                                    args.min_lr, args.lr)\n",
    "                writer.add_scalar(\"lr\", utils.get_lr(optimizer), state[\"step\"])\n",
    "\n",
    "                # Compute loss for each instrument/model\n",
    "                optimizer.zero_grad()\n",
    "                outputs, avg_loss = model_utils.compute_loss(model, x, targets, criterion, compute_grad=True)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                t = time.time() - t\n",
    "                avg_time += (1. / float(example_num + 1)) * (t - avg_time)\n",
    "\n",
    "                writer.add_scalar(\"train_loss\", avg_loss, state[\"step\"])\n",
    "\n",
    "                if example_num % args.example_freq == 0 and args.save_audio_to_logs:\n",
    "                    input_centre = torch.mean(\n",
    "                        x[0, :, model.shapes[\"output_start_frame\"]:model.shapes[\"output_end_frame\"]],\n",
    "                        0)  # Stereo not supported for logs yet\n",
    "                    writer.add_audio(\"input\", input_centre, state[\"step\"], sample_rate=args.sr)\n",
    "\n",
    "                    for inst in outputs.keys():\n",
    "                        writer.add_audio(inst + \"_pred\", torch.mean(outputs[inst][0], 0), state[\"step\"],\n",
    "                                         sample_rate=args.sr)\n",
    "                        writer.add_audio(inst + \"_target\", torch.mean(targets[inst][0], 0), state[\"step\"],\n",
    "                                         sample_rate=args.sr)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        # VALIDATE\n",
    "        val_loss = validate(args, model, criterion, val_data)\n",
    "        print(\"VALIDATION FINISHED: LOSS: \" + str(val_loss))\n",
    "        writer.add_scalar(\"val_loss\", val_loss, state[\"step\"])\n",
    "\n",
    "        # EARLY STOPPING CHECK\n",
    "        checkpoint_path_previous = None\n",
    "        try:\n",
    "            checkpoint_path_previous = state[\"best_checkpoint\"]\n",
    "        except:\n",
    "            print(f\"No 'best_checkpoint' yet\")\n",
    "        \n",
    "        checkpoint_path = os.path.join(args.checkpoint_dir, \"checkpoint_\" + str(state[\"step\"]))            \n",
    "        if val_loss >= state[\"best_loss\"]:\n",
    "            state[\"worse_epochs\"] += 1\n",
    "        else:\n",
    "            print(\"MODEL IMPROVED ON VALIDATION SET!\")\n",
    "          \n",
    "            state[\"worse_epochs\"] = 0\n",
    "            state[\"best_loss\"] = val_loss\n",
    "            state[\"best_checkpoint\"] = checkpoint_path\n",
    "            \n",
    "        state[\"epochs\"] += 1\n",
    "        n_down_sampling = 1\n",
    "        if state[\"epochs\"] % n_down_sampling == 0:\n",
    "            try:\n",
    "                if os.path.exists(checkpoint_path_previous):\n",
    "                    print(f\"Removing old file {checkpoint_path_previous}\")\n",
    "                    os.remove(checkpoint_path_previous)\n",
    "            except:\n",
    "                print(f\"No '{checkpoint_path_previous}' file found!\")           \n",
    "            \n",
    "            # CHECKPOINT\n",
    "            print(\"Saving model...\")\n",
    "            model_utils.save_model(model, optimizer, state, checkpoint_path)\n",
    "            \n",
    "#     #### TESTING ####\n",
    "#     # Test loss\n",
    "#     print(\"TESTING\")\n",
    "\n",
    "#     # Load best model based on validation loss\n",
    "#     state = model_utils.load_model(model, None, state[\"best_checkpoint\"], args.cuda)\n",
    "#     test_loss = validate(args, model, criterion, test_data)\n",
    "#     print(\"TEST FINISHED: LOSS: \" + str(test_loss))\n",
    "#     writer.add_scalar(\"test_loss\", test_loss, state[\"step\"])\n",
    "\n",
    "#     # Mir_eval metrics\n",
    "#     test_metrics = evaluate(args, musdb[\"test\"], model, args.instruments)\n",
    "\n",
    "#     # Dump all metrics results into pickle file for later analysis if needed\n",
    "#     with open(os.path.join(args.checkpoint_dir, \"results.pkl\"), \"wb\") as f:\n",
    "#         pickle.dump(test_metrics, f)\n",
    "\n",
    "#     # Write most important metrics into Tensorboard log\n",
    "#     avg_SDRs = {inst: np.mean([np.nanmean(song[inst][\"SDR\"]) for song in test_metrics]) for inst in args.instruments}\n",
    "#     avg_SIRs = {inst: np.mean([np.nanmean(song[inst][\"SIR\"]) for song in test_metrics]) for inst in args.instruments}\n",
    "#     for inst in args.instruments:\n",
    "#         writer.add_scalar(\"test_SDR_\" + inst, avg_SDRs[inst], state[\"step\"])\n",
    "#         writer.add_scalar(\"test_SIR_\" + inst, avg_SIRs[inst], state[\"step\"])\n",
    "#     overall_SDR = np.mean([v for v in avg_SDRs.values()])\n",
    "#     writer.add_scalar(\"test_SDR\", overall_SDR)\n",
    "#     print(\"SDR: \" + str(overall_SDR))\n",
    "\n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc43a0ba-9114-4fc5-8905-1a895861aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--instruments', type=str, nargs='+', default=[\"other\", \"Eu-152\"],\n",
    "                    help=\"List of instruments to separate (default: \\\"Ru-106 Co-60 other\\\")\")\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='Use CUDA (default: False)')\n",
    "parser.add_argument('--features', type=int, default=int(env['FEATURES']),\n",
    "                    help='Number of feature channels per layer')\n",
    "parser.add_argument('--load_model', type=str, default = None if env['LOAD_MODEL'] == 'None' else env['LOAD_MODEL'],\n",
    "                    help='Reload a previously trained model')\n",
    "parser.add_argument('--batch_size', type=int, default=int(env['BATCH_SIZE']),\n",
    "                    help=\"Batch size\")\n",
    "parser.add_argument('--levels', type=int, default=6,\n",
    "                    help=\"Number of DS/US blocks\")\n",
    "parser.add_argument('--depth', type=int, default=int(env['DEPTH']),\n",
    "                    help=\"Number of convs per block\")\n",
    "parser.add_argument('--sr', type=int, default=int(env['SR']), help=\"Sampling rate\")\n",
    "parser.add_argument('--channels', type=int, default=int(env['CHANNELS']), help=\"Number of input audio channels\")\n",
    "parser.add_argument('--kernel_size', type=int, default=int(env['KERNEL_SIZE']),\n",
    "                    help=\"Filter width of kernels. Has to be an odd number\")\n",
    "parser.add_argument('--output_size', type=float, default=float(env['OUTPUT_SIZE']),\n",
    "                    help=\"Output duration\")\n",
    "parser.add_argument('--strides', type=int, default=int(env['STRIDES']),\n",
    "                    help=\"Strides in Waveunet\")\n",
    "parser.add_argument('--conv_type', type=str, default=str(env['CONV_TYPE']),\n",
    "                    help=\"Type of convolution (normal, BN-normalised, GN-normalised): normal/bn/gn\")\n",
    "parser.add_argument('--res', type=str, default=str(env['RES']),\n",
    "                    help=\"Resampling strategy: fixed sinc-based lowpass filtering or learned conv layer: fixed/learned\")\n",
    "parser.add_argument('--separate', type=int, default=int(env['SEPARATE']),\n",
    "                    help=\"Train separate model for each source (1) or only one (0)\")\n",
    "parser.add_argument('--feature_growth', type=str, default=str(env['FEATURE_GROWTH']),\n",
    "                    help=\"How the features in each layer should grow, either (add) the initial number of features each time, or multiply by 2 (double)\")\n",
    "parser.add_argument('--output', type=str, default = None if env['OUTPUT'] == 'None' else env['OUTPUT'], help=\"Output path (same folder as input path if not set)\")\n",
    "parser.add_argument('--num_workers', type=int, default=int(env['NUM_WORKERS']),\n",
    "                    help='Number of data loader worker threads (default: 1)')\n",
    "parser.add_argument('--log_dir', type=str, default=str(env['LOG_DIR']),\n",
    "                    help='Folder to write logs into')\n",
    "parser.add_argument('--dataset_dir', type=str, default = str(env['DATASET_DIR']),\n",
    "                    help='Dataset path')\n",
    "parser.add_argument('--hdf_dir', type=str, default=str(env['HDF_DIR']),\n",
    "                    help='Dataset path')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default = str(env['CHECKPOINT_DIR']),\n",
    "                    help='Folder to write checkpoints into')\n",
    "parser.add_argument('--lr', type=float, default=float(env['LR']),\n",
    "                    help='Initial learning rate in LR cycle (default: 1e-3)')\n",
    "parser.add_argument('--min_lr', type=float, default=float(env['MIN_LR']),\n",
    "                    help='Minimum learning rate in LR cycle (default: 5e-5)')\n",
    "parser.add_argument('--cycles', type=int, default=int(env['CYCLES']),\n",
    "                    help='Number of LR cycles per epoch')\n",
    "parser.add_argument('--patience', type=int, default=int(env['PATIENCE']),\n",
    "                    help=\"Patience for early stopping on validation set\")\n",
    "parser.add_argument('--example_freq', type=int, default=int(env['EXAMPLE_FREQ']),\n",
    "                    help=\"Write an audio summary into Tensorboard logs every X training iterations\")\n",
    "parser.add_argument('--loss', type=str, default=str(env['LOSS']),\n",
    "                    help=\"L1 or L2\")\n",
    "parser.add_argument('--save_audio_to_logs', type=bool, default=False,\n",
    "                    help=\"Whether to add output with audio samples from training to log in tensorboard (True) or (False)\")\n",
    "\n",
    "args = parser.parse_args(\"--cuda\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "235db144-4389-49d6-ada9-128c9c27e7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 01:31:25 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using valid convolutions with 21161 inputs and 11609 outputs\n",
      "move model to gpu\n",
      "model:  DataParallel(\n",
      "  (module): Waveunet(\n",
      "    (waveunets): ModuleDict(\n",
      "      (other): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (Eu-152): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "parameter count:  35073730\n",
      "Loading train set...\n",
      "Loading test set...\n",
      "TRAINING START\n",
      "Training one epoch from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.50it/s]                                                                                                \n",
      "Current loss: 0.0090: : 31it [00:00, 42.50it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.008977304334797325\n",
      "No 'best_checkpoint' yet\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "No 'None' file found!\n",
      "Saving model...\n",
      "Training one epoch from iteration 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.62it/s]                                                                                                \n",
      "Current loss: 0.0069: : 31it [00:00, 42.94it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006913157010961684\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_122\n",
      "Saving model...\n",
      "Training one epoch from iteration 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.23it/s]                                                                                                \n",
      "Current loss: 0.0068: : 31it [00:00, 43.03it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006782663486627561\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_244\n",
      "Saving model...\n",
      "Training one epoch from iteration 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.59it/s]                                                                                                \n",
      "Current loss: 0.0062: : 31it [00:00, 37.31it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006242750062336844\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_366\n",
      "Saving model...\n",
      "Training one epoch from iteration 488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.56it/s]                                                                                                \n",
      "Current loss: 0.0066: : 31it [00:00, 36.75it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006632532946945679\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_488\n",
      "Saving model...\n",
      "Training one epoch from iteration 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.47it/s]                                                                                                \n",
      "Current loss: 0.0062: : 31it [00:00, 42.60it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006223188452197299\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.55it/s]                                                                                                \n",
      "Current loss: 0.0062: : 31it [00:00, 36.86it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006216389260389992\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_732\n",
      "Saving model...\n",
      "Training one epoch from iteration 854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.15it/s]                                                                                                \n",
      "Current loss: 0.0061: : 31it [00:00, 41.56it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006128672666231831\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_854\n",
      "Saving model...\n",
      "Training one epoch from iteration 976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.44it/s]                                                                                                \n",
      "Current loss: 0.0061: : 31it [00:00, 43.02it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006054586312177802\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_976\n",
      "Saving model...\n",
      "Training one epoch from iteration 1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.52it/s]                                                                                                \n",
      "Current loss: 0.0060: : 31it [00:00, 36.79it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006031301150458955\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1098\n",
      "Saving model...\n",
      "Training one epoch from iteration 1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.09it/s]                                                                                                \n",
      "Current loss: 0.0058: : 31it [00:00, 42.78it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0058444470595268\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1220\n",
      "Saving model...\n",
      "Training one epoch from iteration 1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.90it/s]                                                                                                \n",
      "Current loss: 0.0060: : 31it [00:00, 42.47it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.006047588728007771\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1342\n",
      "Saving model...\n",
      "Training one epoch from iteration 1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.56it/s]                                                                                                \n",
      "Current loss: 0.0057: : 31it [00:00, 41.67it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.005712734325037849\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.18it/s]                                                                                                \n",
      "Current loss: 0.0054: : 31it [00:00, 42.17it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0054486819670625745\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1586\n",
      "Saving model...\n",
      "Training one epoch from iteration 1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.48it/s]                                                                                                \n",
      "Current loss: 0.0050: : 31it [00:00, 42.89it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.004984380996545717\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1708\n",
      "Saving model...\n",
      "Training one epoch from iteration 1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.51it/s]                                                                                                \n",
      "Current loss: 0.0048: : 31it [00:00, 37.42it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.004762519334983681\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1830\n",
      "Saving model...\n",
      "Training one epoch from iteration 1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.22it/s]                                                                                                \n",
      "Current loss: 0.0047: : 31it [00:00, 43.12it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.004741677514938337\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_1952\n",
      "Saving model...\n",
      "Training one epoch from iteration 2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.94it/s]                                                                                                \n",
      "Current loss: 0.0048: : 31it [00:00, 42.50it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0048056178061561955\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2074\n",
      "Saving model...\n",
      "Training one epoch from iteration 2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.62it/s]                                                                                                \n",
      "Current loss: 0.0045: : 31it [00:00, 43.01it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0045395003004570405\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.19it/s]                                                                                                \n",
      "Current loss: 0.0040: : 31it [00:00, 42.07it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.004009166285545834\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2318\n",
      "Saving model...\n",
      "Training one epoch from iteration 2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.56it/s]                                                                                                \n",
      "Current loss: 0.0039: : 31it [00:00, 42.92it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.003913064094846167\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2440\n",
      "Saving model...\n",
      "Training one epoch from iteration 2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.25it/s]                                                                                                \n",
      "Current loss: 0.0033: : 31it [00:00, 41.67it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0033148106623200634\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2562\n",
      "Saving model...\n",
      "Training one epoch from iteration 2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.26it/s]                                                                                                \n",
      "Current loss: 0.0033: : 31it [00:00, 42.57it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0033207242752635677\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2684\n",
      "Saving model...\n",
      "Training one epoch from iteration 2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 22.00it/s]                                                                                                \n",
      "Current loss: 0.0033: : 31it [00:00, 42.80it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0032981496826264885\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.31it/s]                                                                                                \n",
      "Current loss: 0.0032: : 31it [00:00, 43.09it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.003180725441779941\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_2928\n",
      "Saving model...\n",
      "Training one epoch from iteration 3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.20it/s]                                                                                                \n",
      "Current loss: 0.0028: : 31it [00:00, 42.34it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002824641570764323\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_3050\n",
      "Saving model...\n",
      "Training one epoch from iteration 3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.60it/s]                                                                                                \n",
      "Current loss: 0.0031: : 31it [00:00, 42.78it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0030507814954034984\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_3172\n",
      "Saving model...\n",
      "Training one epoch from iteration 3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.23it/s]                                                                                                \n",
      "Current loss: 0.0025: : 31it [00:00, 42.90it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002544474571139642\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.25it/s]                                                                                                \n",
      "Current loss: 0.0027: : 31it [00:00, 43.09it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002674049483762393\n",
      "Removing old file /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/checkpoints/checkpoint_3416\n",
      "Saving model...\n",
      "Training one epoch from iteration 3538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [00:05, 21.86it/s]                                                                                                \n",
      "Current loss: 0.0025: : 31it [00:00, 43.10it/s]                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0025466017945173893\n",
      "Saving model...\n",
      "done training\n"
     ]
    }
   ],
   "source": [
    "experiment_name = str(env['EXPERIMENT_NAME'])\n",
    "registry_uri_name = str(env['REGISTRY_URI_NAME'])\n",
    "tracking_uri_name = str(env['TRACKING_URI_NAME'])\n",
    "\n",
    "mlflow.set_registry_uri(registry_uri_name)\n",
    "mlflow.set_tracking_uri(tracking_uri_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# enable autologging\n",
    "mlflow.pytorch.autolog()\n",
    "    \n",
    "# with mlflow.start_run(description=\"Experiments with decomposition of nuclide 'Eu152' from GammaSpectraGeant4\"):\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"--mlflow_version\", f\"{mlflow.version.VERSION}\")\n",
    "    mlflow.log_param(\"--registry_uri\", f\"{mlflow.get_registry_uri()}\")\n",
    "    mlflow.log_param(\"--tracking_uri\", f\"{mlflow.get_tracking_uri()}\")\n",
    "    \n",
    "    mlflow.set_tag(\"load_model\", f\"{str(env['LOAD_MODEL'])}\")\n",
    "\n",
    "    mlflow.log_param(\"--cuda\", f\"{args.cuda}\")\n",
    "    mlflow.log_param(\"--features\", int(env['FEATURES']))\n",
    "    mlflow.log_param(\"--load_model\", None if env['LOAD_MODEL'] == 'None' else env['LOAD_MODEL'])\n",
    "    mlflow.log_param(\"--batch_size\", int(env['BATCH_SIZE']))\n",
    "    mlflow.log_param(\"--depth\", int(env['DEPTH']))\n",
    "    mlflow.log_param(\"--sampling_rate\", int(env['SR']))\n",
    "    mlflow.log_param(\"--kernel_size\", int(env['KERNEL_SIZE']))\n",
    "    mlflow.log_param(\"--output_size\", float(env['OUTPUT_SIZE']))\n",
    "    mlflow.log_param(\"--strides\", int(env['STRIDES']))\n",
    "    mlflow.log_param(\"--conv_type\", str(env['CONV_TYPE']))\n",
    "    mlflow.log_param(\"--res\", str(env['RES']))\n",
    "    mlflow.log_param(\"--separate\", int(env['SEPARATE']))\n",
    "    mlflow.log_param(\"--output\", None if env['OUTPUT'] == 'None' else env['OUTPUT'])\n",
    "    mlflow.log_param(\"--log_dir\", str(env['LOG_DIR']))\n",
    "    mlflow.log_param(\"--dataset_dir\", str(env['DATASET_DIR']))\n",
    "    mlflow.log_param(\"--hdf_dir\", str(env['HDF_DIR']))\n",
    "    mlflow.log_param(\"--checkpoint_dir\", str(env['CHECKPOINT_DIR']))\n",
    "    mlflow.log_param(\"--lr\", str(env['LR']))\n",
    "    mlflow.log_param(\"--patience\", str(env['PATIENCE']))\n",
    "    \n",
    "    model = main(args)\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    mlflow.log_metric(\"--val_loss\", float(\"nan\"))\n",
    "print(\"done training\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493cd70-29f3-4fe4-b33f-47c7a3bbb9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
