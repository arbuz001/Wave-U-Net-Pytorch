{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4962ddc1-9ee5-4e23-afba-4baa08490c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import model.utils as model_utils\n",
    "import utils\n",
    "from data.dataset import SeparationDataset\n",
    "from data.musdb import get_musdb_folds\n",
    "from data.utils import crop_targets, random_amplify\n",
    "from model.waveunet import Waveunet\n",
    "from test import evaluate, validate\n",
    "from os import environ as env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1058462-0a4f-481a-ba9c-93dff394c49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load env variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o -v ./config/config_train.yml\n",
    "# %reload_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082b8991-653c-4f45-a9d6-168fe67a7c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # torch.backends.cudnn.benchmark=True # This makes dilated conv much faster for CuDNN 7.5\n",
    "\n",
    "    # MODEL\n",
    "    num_features = [args.features * i for i in range(1, args.levels + 1)] if args.feature_growth == \"add\" else \\\n",
    "        [args.features * 2 ** i for i in range(0, args.levels)]\n",
    "    target_outputs = int(args.output_size * args.sr)\n",
    "    model = Waveunet(args.channels, num_features, args.channels, args.instruments, kernel_size=args.kernel_size,\n",
    "                     target_output_size=target_outputs, depth=args.depth, strides=args.strides,\n",
    "                     conv_type=args.conv_type, res=args.res, separate=args.separate)\n",
    "\n",
    "    if args.cuda:\n",
    "        model = model_utils.DataParallel(model)\n",
    "        print(\"move model to gpu\")\n",
    "        model.cuda()\n",
    "\n",
    "    print('model: ', model)\n",
    "    print('parameter count: ', str(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "    writer = SummaryWriter(args.log_dir)\n",
    "\n",
    "    ### DATASET\n",
    "    musdb = get_musdb_folds(args.dataset_dir)\n",
    "    # If not data augmentation, at least crop targets to fit model output shape\n",
    "    crop_func = partial(crop_targets, shapes=model.shapes)\n",
    "    # Data augmentation function for training\n",
    "    augment_func = partial(random_amplify, shapes=model.shapes, min=0.7, max=1.0)\n",
    "    train_data = SeparationDataset(musdb, \"train\", args.instruments, args.sr, args.channels, model.shapes, True,\n",
    "                                   args.hdf_dir, audio_transform=augment_func)\n",
    "    val_data = SeparationDataset(musdb, \"val\", args.instruments, args.sr, args.channels, model.shapes, False,\n",
    "                                 args.hdf_dir, audio_transform=crop_func)\n",
    "    test_data = SeparationDataset(musdb, \"test\", args.instruments, args.sr, args.channels, model.shapes, False,\n",
    "                                  args.hdf_dir, audio_transform=crop_func)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(train_data, batch_size=args.batch_size, shuffle=True,\n",
    "                                             num_workers=args.num_workers, worker_init_fn=utils.worker_init_fn)\n",
    "\n",
    "    ##### TRAINING ####\n",
    "\n",
    "    # Set up the loss function\n",
    "    if args.loss == \"L1\":\n",
    "        criterion = nn.L1Loss()\n",
    "    elif args.loss == \"L2\":\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"Couldn't find this loss!\")\n",
    "\n",
    "    # Set up optimiser\n",
    "    optimizer = Adam(params=model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Set up training state dict that will also be saved into checkpoints\n",
    "    state = {\"step\": 0,\n",
    "             \"worse_epochs\": 0,\n",
    "             \"epochs\": 0,\n",
    "             \"best_loss\": np.Inf}\n",
    "\n",
    "    # LOAD MODEL CHECKPOINT IF DESIRED\n",
    "    if args.load_model is not None:\n",
    "        print(\"Continuing training full model from checkpoint \" + str(args.load_model))\n",
    "        state = model_utils.load_model(model, optimizer, args.load_model, args.cuda)\n",
    "\n",
    "    print('TRAINING START')\n",
    "\n",
    "    while state[\"worse_epochs\"] < args.patience:\n",
    "        print(\"Training one epoch from iteration \" + str(state[\"step\"]))\n",
    "        avg_time = 0.\n",
    "        model.train()\n",
    "        with tqdm(total=len(train_data) // args.batch_size) as pbar:\n",
    "            np.random.seed()\n",
    "            for example_num, (x, targets) in enumerate(dataloader):\n",
    "                if args.cuda:\n",
    "                    x = x.cuda()\n",
    "                    for k in list(targets.keys()):\n",
    "                        targets[k] = targets[k].cuda()\n",
    "\n",
    "                t = time.time()\n",
    "\n",
    "                # Set LR for this iteration\n",
    "                utils.set_cyclic_lr(optimizer, example_num, len(train_data) // args.batch_size, args.cycles,\n",
    "                                    args.min_lr, args.lr)\n",
    "                writer.add_scalar(\"lr\", utils.get_lr(optimizer), state[\"step\"])\n",
    "\n",
    "                # Compute loss for each instrument/model\n",
    "                optimizer.zero_grad()\n",
    "                outputs, avg_loss = model_utils.compute_loss(model, x, targets, criterion, compute_grad=True)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "\n",
    "                t = time.time() - t\n",
    "                avg_time += (1. / float(example_num + 1)) * (t - avg_time)\n",
    "\n",
    "                writer.add_scalar(\"train_loss\", avg_loss, state[\"step\"])\n",
    "\n",
    "                if example_num % args.example_freq == 0 and args.save_audio_to_logs:\n",
    "                    input_centre = torch.mean(\n",
    "                        x[0, :, model.shapes[\"output_start_frame\"]:model.shapes[\"output_end_frame\"]],\n",
    "                        0)  # Stereo not supported for logs yet\n",
    "                    writer.add_audio(\"input\", input_centre, state[\"step\"], sample_rate=args.sr)\n",
    "\n",
    "                    for inst in outputs.keys():\n",
    "                        writer.add_audio(inst + \"_pred\", torch.mean(outputs[inst][0], 0), state[\"step\"],\n",
    "                                         sample_rate=args.sr)\n",
    "                        writer.add_audio(inst + \"_target\", torch.mean(targets[inst][0], 0), state[\"step\"],\n",
    "                                         sample_rate=args.sr)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        # VALIDATE\n",
    "        val_loss = validate(args, model, criterion, val_data)\n",
    "        print(\"VALIDATION FINISHED: LOSS: \" + str(val_loss))\n",
    "        writer.add_scalar(\"val_loss\", val_loss, state[\"step\"])\n",
    "\n",
    "        # EARLY STOPPING CHECK\n",
    "        checkpoint_path = os.path.join(args.checkpoint_dir, \"checkpoint_\" + str(state[\"step\"]))\n",
    "        if val_loss >= state[\"best_loss\"]:\n",
    "            state[\"worse_epochs\"] += 1\n",
    "        else:\n",
    "            print(\"MODEL IMPROVED ON VALIDATION SET!\")\n",
    "            state[\"worse_epochs\"] = 0\n",
    "            state[\"best_loss\"] = val_loss\n",
    "            state[\"best_checkpoint\"] = checkpoint_path\n",
    "\n",
    "        state[\"epochs\"] += 1\n",
    "        n_down_sampling = 1\n",
    "        if state[\"epochs\"] % n_down_sampling == 0:\n",
    "            # CHECKPOINT\n",
    "            print(\"Saving model...\")\n",
    "            model_utils.save_model(model, optimizer, state, checkpoint_path)\n",
    "\n",
    "    #### TESTING ####\n",
    "    # Test loss\n",
    "    print(\"TESTING\")\n",
    "\n",
    "    # Load best model based on validation loss\n",
    "    state = model_utils.load_model(model, None, state[\"best_checkpoint\"], args.cuda)\n",
    "    test_loss = validate(args, model, criterion, test_data)\n",
    "    print(\"TEST FINISHED: LOSS: \" + str(test_loss))\n",
    "    writer.add_scalar(\"test_loss\", test_loss, state[\"step\"])\n",
    "\n",
    "    # Mir_eval metrics\n",
    "    test_metrics = evaluate(args, musdb[\"test\"], model, args.instruments)\n",
    "\n",
    "    # Dump all metrics results into pickle file for later analysis if needed\n",
    "    with open(os.path.join(args.checkpoint_dir, \"results.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(test_metrics, f)\n",
    "\n",
    "    # Write most important metrics into Tensorboard log\n",
    "    avg_SDRs = {inst: np.mean([np.nanmean(song[inst][\"SDR\"]) for song in test_metrics]) for inst in args.instruments}\n",
    "    avg_SIRs = {inst: np.mean([np.nanmean(song[inst][\"SIR\"]) for song in test_metrics]) for inst in args.instruments}\n",
    "    for inst in args.instruments:\n",
    "        writer.add_scalar(\"test_SDR_\" + inst, avg_SDRs[inst], state[\"step\"])\n",
    "        writer.add_scalar(\"test_SIR_\" + inst, avg_SIRs[inst], state[\"step\"])\n",
    "    overall_SDR = np.mean([v for v in avg_SDRs.values()])\n",
    "    writer.add_scalar(\"test_SDR\", overall_SDR)\n",
    "    print(\"SDR: \" + str(overall_SDR))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc43a0ba-9114-4fc5-8905-1a895861aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--instruments', type=str, nargs='+', default=[\"other\", \"Ru-106\"],\n",
    "                    help=\"List of instruments to separate (default: \\\"Ru-106 Co-60 other\\\")\")\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='Use CUDA (default: False)')\n",
    "parser.add_argument('--features', type=int, default=int(env['FEATURES']),\n",
    "                    help='Number of feature channels per layer')\n",
    "parser.add_argument('--load_model', type=str, default = None if env['LOAD_MODEL'] == 'None' else env['LOAD_MODEL'],\n",
    "                    help='Reload a previously trained model')\n",
    "parser.add_argument('--batch_size', type=int, default=int(env['BATCH_SIZE']),\n",
    "                    help=\"Batch size\")\n",
    "parser.add_argument('--levels', type=int, default=6,\n",
    "                    help=\"Number of DS/US blocks\")\n",
    "parser.add_argument('--depth', type=int, default=int(env['DEPTH']),\n",
    "                    help=\"Number of convs per block\")\n",
    "parser.add_argument('--sr', type=int, default=int(env['SR']), help=\"Sampling rate\")\n",
    "parser.add_argument('--channels', type=int, default=int(env['CHANNELS']), help=\"Number of input audio channels\")\n",
    "parser.add_argument('--kernel_size', type=int, default=int(env['KERNEL_SIZE']),\n",
    "                    help=\"Filter width of kernels. Has to be an odd number\")\n",
    "parser.add_argument('--output_size', type=float, default=float(env['OUTPUT_SIZE']),\n",
    "                    help=\"Output duration\")\n",
    "parser.add_argument('--strides', type=int, default=int(env['STRIDES']),\n",
    "                    help=\"Strides in Waveunet\")\n",
    "parser.add_argument('--conv_type', type=str, default=str(env['CONV_TYPE']),\n",
    "                    help=\"Type of convolution (normal, BN-normalised, GN-normalised): normal/bn/gn\")\n",
    "parser.add_argument('--res', type=str, default=str(env['RES']),\n",
    "                    help=\"Resampling strategy: fixed sinc-based lowpass filtering or learned conv layer: fixed/learned\")\n",
    "parser.add_argument('--separate', type=int, default=int(env['SEPARATE']),\n",
    "                    help=\"Train separate model for each source (1) or only one (0)\")\n",
    "parser.add_argument('--feature_growth', type=str, default=str(env['FEATURE_GROWTH']),\n",
    "                    help=\"How the features in each layer should grow, either (add) the initial number of features each time, or multiply by 2 (double)\")\n",
    "parser.add_argument('--input', type=str, default=str(env['INPUT']),\n",
    "                    help=\"Path to input mixture to be separated\")\n",
    "parser.add_argument('--output', type=str, default = None if env['OUTPUT'] == 'None' else env['OUTPUT'], help=\"Output path (same folder as input path if not set)\")\n",
    "parser.add_argument('--num_workers', type=int, default=int(env['NUM_WORKERS']),\n",
    "                    help='Number of data loader worker threads (default: 1)')\n",
    "parser.add_argument('--log_dir', type=str, default=str(env['LOG_DIR']),\n",
    "                    help='Folder to write logs into')\n",
    "parser.add_argument('--dataset_dir', type=str, default = str(env['DATASET_DIR']),\n",
    "                    help='Dataset path')\n",
    "parser.add_argument('--hdf_dir', type=str, default=str(env['HDF_DIR']),\n",
    "                    help='Dataset path')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default = str(env['CHECKPOINT_DIR']),\n",
    "                    help='Folder to write checkpoints into')\n",
    "parser.add_argument('--lr', type=float, default=float(env['LR']),\n",
    "                    help='Initial learning rate in LR cycle (default: 1e-3)')\n",
    "parser.add_argument('--min_lr', type=float, default=float(env['MIN_LR']),\n",
    "                    help='Minimum learning rate in LR cycle (default: 5e-5)')\n",
    "parser.add_argument('--cycles', type=int, default=int(env['CYCLES']),\n",
    "                    help='Number of LR cycles per epoch')\n",
    "parser.add_argument('--patience', type=int, default=int(env['PATIENCE']),\n",
    "                    help=\"Patience for early stopping on validation set\")\n",
    "parser.add_argument('--example_freq', type=int, default=int(env['EXAMPLE_FREQ']),\n",
    "                    help=\"Write an audio summary into Tensorboard logs every X training iterations\")\n",
    "parser.add_argument('--loss', type=str, default=str(env['LOSS']),\n",
    "                    help=\"L1 or L2\")\n",
    "parser.add_argument('--save_audio_to_logs', type=bool, default=False,\n",
    "                    help=\"Whether to add output with audio samples from training to log in tensorboard (True) or (False)\")\n",
    "\n",
    "args = parser.parse_args(\"--cuda\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d20539-ae61-4ec0-840e-38283091ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using valid convolutions with 21161 inputs and 11609 outputs\n",
      "move model to gpu\n",
      "model:  DataParallel(\n",
      "  (module): Waveunet(\n",
      "    (waveunets): ModuleDict(\n",
      "      (other): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (Ru-106): Module(\n",
      "        (downsampling_blocks): ModuleList(\n",
      "          (0): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (1): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (2): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (3): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "          (4): DownsamplingBlock(\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 1024, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (downconv): Resample1d()\n",
      "          )\n",
      "        )\n",
      "        (upsampling_blocks): ModuleList(\n",
      "          (0): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(1024, 512, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(64, 512, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(512, 256, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(128, 64, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (4): UpsamplingBlock(\n",
      "            (upconv): Resample1d()\n",
      "            (pre_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "            (post_shortcut_convs): ModuleList(\n",
      "              (0): ConvLayer(\n",
      "                (filter): Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
      "                (norm): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (bottlenecks): ModuleList(\n",
      "          (0): ConvLayer(\n",
      "            (filter): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,))\n",
      "            (norm): GroupNorm(128, 1024, eps=1e-05, affine=True)\n",
      "          )\n",
      "        )\n",
      "        (output_conv): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "parameter count:  35073730\n",
      "Loading train set...\n",
      "Loading test set...\n",
      "TRAINING START\n",
      "Training one epoch from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 151/151 [00:10<00:00, 14.89it/s]\n",
      "Current loss: 0.0028: 100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 42.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.0028284206024469117\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 151/151 [00:06<00:00, 22.29it/s]\n",
      "Current loss: 0.0025: 100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 42.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002508215387933887\n",
      "MODEL IMPROVED ON VALIDATION SET!\n",
      "Saving model...\n",
      "Training one epoch from iteration 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 151/151 [00:06<00:00, 22.36it/s]\n",
      "Current loss: 0.0025: 100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 40.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002518626401740077\n",
      "Saving model...\n",
      "Training one epoch from iteration 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 151/151 [00:06<00:00, 21.99it/s]\n",
      "Current loss: 0.0026: 100%|█████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 44.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION FINISHED: LOSS: 0.002605117986125773\n",
      "Saving model...\n",
      "TESTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current loss: 0.0021: 100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST FINISHED: LOSS: 0.0020520631473378405\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-1/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-10/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-11/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-12/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-13/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-14/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-15/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-16/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-17/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-18/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-19/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-2/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-20/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-21/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-22/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-23/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-24/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-25/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-26/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-27/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-28/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-29/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-3/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-30/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-31/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-32/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-33/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-34/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-35/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-36/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-37/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-38/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-39/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-4/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-40/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-41/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-42/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-43/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-44/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-45/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-46/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-47/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-48/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-49/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-5/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-50/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-51/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-52/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-53/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-54/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-55/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-56/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-57/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-58/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-59/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-6/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-60/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-61/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-62/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-63/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-64/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-65/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-66/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-67/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-68/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-69/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-7/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-70/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-71/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-72/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-73/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-74/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-75/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-76/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-77/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-78/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-79/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-8/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-80/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-81/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-82/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-83/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-84/mixture.wav\n",
      "Evaluating /home/aarbuzov/work-and-study/git/Wave-U-Net-Pytorch/musdb18hq_geant4_2_classes_sr11025_n=840/test/mixture-9/mixture.wav\n",
      "SDR: 12.047080723004042\n",
      "done training\n"
     ]
    }
   ],
   "source": [
    "main(args)\n",
    "print(\"done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3279c4-f3ce-4731-ab2d-5043ff302b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
